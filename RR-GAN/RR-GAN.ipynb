{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f620ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe374464",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../data/original_cohort_data.xlsx\", sheet_name=1)\n",
    "boundary = np.array(pd.read_excel(\"../data/feature_constraints.xlsx\"))\n",
    "minv = boundary[0, :]\n",
    "maxv = boundary[1, :]\n",
    "minv.shape, maxv.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, minv, maxv):\n",
    "    return (x - minv) / (maxv - minv)\n",
    "\n",
    "def unnormalize(nx, minv, maxv):\n",
    "    return nx * (maxv - minv) + minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = normalize(data, minv, maxv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b04b91",
   "metadata": {},
   "source": [
    "## 生成对抗网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310efefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(46, 32),  # 输入特征数为784，输出为512\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2),  # 进行非线性映射\n",
    "            nn.Linear(32, 16),  # 进行一个线性映射\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # 也是一个激活函数，二分类问题中，\n",
    "            # sigmoid可以班实数映射到【0,1】，作为概率值，\n",
    "            # 多分类用softmax函数\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    "\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(5, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(32, 46),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.array(ndata)\n",
    "data_train = torch.FloatTensor(data_train)\n",
    "\n",
    "criterion = nn.BCELoss()  # 是单目标二分类交叉熵函数\n",
    "D = discriminator()\n",
    "G = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10**5\n",
    "z_dimension = 5\n",
    "\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     D = D.cuda()\n",
    "#     G = G.cuda()\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.00001)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epoch):  # 进行多个epoch的训练\n",
    "    num_sample = data_train.shape[0]\n",
    "    \n",
    "    real_label = torch.ones(num_sample, 1)\n",
    "    fake_label = torch.zeros(num_sample, 1)\n",
    "    # 计算真实图片的损失\n",
    "    real_out = D(data_train)  # 将真实图片放入判别器中\n",
    "    d_loss_real = criterion(real_out, real_label)  # 得到真实图片的loss\n",
    "    real_scores = real_out  # 得到真实图片的判别值，输出的值越接近1越好\n",
    "    # 计算假的图片的损失\n",
    "    z = torch.randn(num_sample, z_dimension)\n",
    "    fake_sample = G(z)  # 随机噪声放入生成网络中，生成一张假的图片\n",
    "    fake_out = D(fake_sample)  # 判别器判断假的图片\n",
    "    d_loss_fake = criterion(fake_out, fake_label)  # 得到假的图片的loss\n",
    "    fake_scores = fake_out  # 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "    # 损失函数和优化\n",
    "    d_loss = d_loss_real + d_loss_fake  # 损失包括判真损失和判假损失\n",
    "    d_optimizer.zero_grad()  # 在反向传播之前，先将梯度归0\n",
    "    d_loss.backward()  # 将误差反向传播\n",
    "    d_optimizer.step()  # 更新参数\n",
    "    # ==================训练生成器============================\n",
    "    z = torch.randn(num_sample, z_dimension) # 得到随机噪声\n",
    "    fake_sample = G(z)  # 随机噪声输入到生成器中，得到一副假的图片\n",
    "    output = D(fake_sample)  # 经过判别器得到的结果\n",
    "    g_loss = criterion(output, real_label)  # 得到的假的图片与真实的图片的label的loss\n",
    "    # bp and optimize\n",
    "    g_optimizer.zero_grad()  # 梯度归0\n",
    "    g_loss.backward()  # 进行反向传播\n",
    "    g_optimizer.step()  # .step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "    # 打印中间的损失\n",
    "    if epoch % 1000 == 0:\n",
    "        print('Epoch[{}/{}],d_loss:{:.6f},g_loss:{:.6f} '\n",
    "              'D real: {:.6f},D fake: {:.6f}'.format(\n",
    "            epoch, num_epoch, d_loss.data.item(), g_loss.data.item(),\n",
    "            real_scores.data.mean(), fake_scores.data.mean()  # 打印的是真实图片的损失均值\n",
    "        ))\n",
    "#     if epoch == 0 and i==len(dataloader)-1:\n",
    "#         real_images = to_img(real_img.cuda().data)\n",
    "#         save_image(real_images, './img2/real_images.png')\n",
    "#     if i==len(dataloader)-1:\n",
    "#         fake_images = to_img(fake_img.cuda().data)\n",
    "#         save_image(fake_images, './img2/fake_images-{}.png'.format(epoch + 1))\n",
    "# # 保存模型\n",
    "# torch.save(G.state_dict(), './generator.pth')\n",
    "# torch.save(D.state_dict(), './discriminator.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd25c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (你之前的 RR-GAN 生成代码) ...\n",
    "\n",
    "# 1. 动态获取正确的指标名称\n",
    "# 你的代码里已经读取了 data，并且 drop 掉了 \"序号\"\n",
    "# data = pd.read_excel(\"../data/JM.xlsx\", sheet_name=1).drop(\"序号\", axis=1)\n",
    "feature_columns = data.columns  # 直接获取列名，绝对不会错\n",
    "\n",
    "# 2. 生成模拟数据 (与你之前的逻辑保持一致)\n",
    "fake_num = 171\n",
    "save_name = \"synthetic_augmented_data.xlsx\"  # 注意这里我改成了 .xlsx\n",
    "\n",
    "z = torch.randn(fake_num, z_dimension)\n",
    "fake_sample = G(z).detach().numpy()\n",
    "fake_sample = unnormalize(fake_sample, minv, maxv)\n",
    "\n",
    "# 3. 关键步骤：将 numpy 数组转换为带列名的 DataFrame\n",
    "# 这样生成的 Excel 第一行就是你原始数据里的指标名称\n",
    "df_fake = pd.DataFrame(fake_sample, columns=feature_columns)\n",
    "\n",
    "# 4. 保存为 Excel，方便后续 XGBoost 读取\n",
    "df_fake.to_excel(\"../data/%s\" % save_name, index=False)\n",
    "\n",
    "print(f\"File saved successfully: {save_name}\")\n",
    "print(f\"Data Shape: {df_fake.shape}\")\n",
    "print(f\"Columns: {list(df_fake.columns)}\") # 打印出来确认一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be101f-6e12-4b8d-bf41-5f2bebb5bc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xgb_gpu_env)",
   "language": "python",
   "name": "xgb_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d330885aeb5bc38bbdda26e3e3241df7789a4a394e63682444f6e4cf96f8cea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
